{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "493e40f2-ba94-403e-b7d7-1368f08a5724",
      "metadata": {
        "id": "493e40f2-ba94-403e-b7d7-1368f08a5724"
      },
      "source": [
        "## Colab Notebook for Building a RAG System with LLAMAIndex and OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "848d6845-3ea0-482c-8d30-257363b5e8bc",
      "metadata": {
        "id": "848d6845-3ea0-482c-8d30-257363b5e8bc"
      },
      "source": [
        "Open this notebook in [colab](https://colab.research.google.com/github/Chair-of-Banking-and-Finance/Bachelor_thesis_24_25_Template/blob/main/GPT_RAG/rag_openAI.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae15763-f117-4f0f-bb72-9255539129ff",
      "metadata": {
        "id": "7ae15763-f117-4f0f-bb72-9255539129ff"
      },
      "source": [
        "### Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5166522-0234-48c8-9d6b-3af1f848c831",
      "metadata": {
        "id": "a5166522-0234-48c8-9d6b-3af1f848c831"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index\n",
        "!pip install openai\n",
        "!pip install faiss-cpu\n",
        "!pip install requests\n",
        "!pip install PyMuPDF\n",
        "!pip install llama-index-vector-stores-faiss\n",
        "!pip install chromadb\n",
        "!pip install llama-index-vector-stores-chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58ab060d-54a5-4c85-8b23-f2f95c8cf384",
      "metadata": {
        "id": "58ab060d-54a5-4c85-8b23-f2f95c8cf384"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf01b6dc-4bf9-4b1a-8c56-1182a5836924",
      "metadata": {
        "id": "cf01b6dc-4bf9-4b1a-8c56-1182a5836924"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import faiss\n",
        "import numpy as np\n",
        "import fitz  # PyMuPDF for PDF handling\n",
        "from llama_index.core import VectorStoreIndex, ServiceContext, PromptTemplate, Document, StorageContext, SimpleDirectoryReader, load_index_from_storage\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.vector_stores.faiss import FaissVectorStore\n",
        "import chromadb\n",
        "from llama_index.vector_stores.chroma.base import ChromaVectorStore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57611c79-779f-4495-89f2-405a7a869b82",
      "metadata": {
        "id": "57611c79-779f-4495-89f2-405a7a869b82"
      },
      "source": [
        "### Load txt file with the OpenAI key to colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6838a20c-255d-42ed-b8d4-14759f5832b5",
      "metadata": {
        "id": "6838a20c-255d-42ed-b8d4-14759f5832b5"
      },
      "outputs": [],
      "source": [
        "!wget -O OPEN_AI_KEY.txt 'https://raw.githubusercontent.com/Chair-of-Banking-and-Finance/Bachelor_thesis_24_25_Template/main/GPT_RAG/OPEN_AI_KEY.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d22837c4-42cf-4f64-8b46-b551b1cf1af6",
      "metadata": {
        "id": "d22837c4-42cf-4f64-8b46-b551b1cf1af6"
      },
      "source": [
        "### Insert your OpenAI key and overwrite the file with the new content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to Create an OpenAI API Key\n",
        "1. **Sign Up/Log In**: Go to [OpenAI's website](https://platform.openai.com/) and sign up for an account if you don’t already have one, or log in if you do.\n",
        "\n",
        "2. **Navigate to API Keys**: After logging in, go to your account settings (accessible via the user icon at the top-right corner). Select \"API Keys\" from the menu.\n",
        "\n",
        "3. **Create a New Key**: Click on the \"Create API Key\" button. A new API key will be generated. Make sure to copy and save it securely, as you won’t be able to view it again.\n",
        "\n",
        "4. **Use the Key in Your Code**: Reference the key in your code to authenticate requests to the OpenAI API (the line below)."
      ],
      "metadata": {
        "id": "Bc9juMvmGu6d"
      },
      "id": "Bc9juMvmGu6d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jX47fyqNXnYV",
      "metadata": {
        "id": "jX47fyqNXnYV"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = 'sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7516238c-2b30-4285-a9f7-ec1d74dedb87",
      "metadata": {
        "id": "7516238c-2b30-4285-a9f7-ec1d74dedb87"
      },
      "outputs": [],
      "source": [
        "with open('OPEN_AI_KEY.txt', 'w') as file:\n",
        "    file.write(OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa70c96a-1a62-4c69-9a0f-9c98d98c9b5d",
      "metadata": {
        "id": "aa70c96a-1a62-4c69-9a0f-9c98d98c9b5d"
      },
      "source": [
        "### Load OpenAI API key from file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b2100b4-10a4-42d3-9091-96e09c8d8f53",
      "metadata": {
        "id": "6b2100b4-10a4-42d3-9091-96e09c8d8f53"
      },
      "outputs": [],
      "source": [
        "if OPENAI_API_KEY:\n",
        "  openai.api_key=OPENAI_API_KEY\n",
        "else:\n",
        "  with open(\"OPEN_AI_KEY.txt\", \"r\") as key_file:\n",
        "    openai.api_key = key_file.read().strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c365562d-5dd0-4337-ae86-376b1f1156fc",
      "metadata": {
        "id": "c365562d-5dd0-4337-ae86-376b1f1156fc"
      },
      "source": [
        "### Create a 'data' directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa7d112f-7369-4225-85ef-8341d9c45f5e",
      "metadata": {
        "id": "fa7d112f-7369-4225-85ef-8341d9c45f5e"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ab7274-af66-4d90-8302-91ba011ed255",
      "metadata": {
        "id": "05ab7274-af66-4d90-8302-91ba011ed255"
      },
      "source": [
        "### Load text files and convert PDFs from the \"data\" folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rgJHSWCqDi84",
      "metadata": {
        "id": "rgJHSWCqDi84"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define the text to be written to the file\n",
        "roman_empire_text = \"\"\"\n",
        "The Roman Empire: An Overview\n",
        "The Roman Empire was one of the most influential civilizations in human history, spanning over a millennium and leaving a legacy that shaped the world in areas such as governance, architecture, engineering, and law. Officially beginning in 27 BCE with the rise of Augustus Caesar, Rome transitioned from a republic to an empire, dominating vast territories that stretched from Britain in the northwest to Egypt in the southeast.\n",
        "\n",
        "Formation and Expansion\n",
        "The Roman Empire's foundation was built on centuries of conquest during the Roman Republic. Under Augustus, the empire ushered in a period of peace and stability known as the Pax Romana (Roman Peace), lasting about 200 years. During this time, Rome expanded its borders, solidifying control over Europe, North Africa, and parts of the Middle East.\n",
        "\n",
        "The empire was characterized by a vast network of cities connected by advanced roads and aqueducts, facilitating trade, military movements, and cultural exchange. Notable conquests include Gaul (modern-day France) under Julius Caesar, the annexation of Egypt after Cleopatra's defeat, and the consolidation of power in regions such as Spain and the Balkans.\n",
        "\n",
        "Culture and Society\n",
        "Roman society was highly stratified, with a clear distinction between the elite patricians, common plebeians, and enslaved individuals. Roman culture blended Latin traditions with influences from Greece and the regions it conquered. This fusion led to remarkable achievements in literature (Virgil’s Aeneid), philosophy (Cicero, Seneca), and architecture (the Colosseum, aqueducts, and the Pantheon).\n",
        "\n",
        "The Roman Empire was also a melting pot of religions. Initially polytheistic, it later became a cradle for Christianity, with Emperor Constantine legalizing the faith in 313 CE and Emperor Theodosius I declaring it the state religion by 380 CE.\n",
        "\n",
        "Governance and Law\n",
        "Rome was renowned for its administrative prowess and legal systems. The empire was divided into provinces, each governed by an appointed official. Roman law, codified in the Twelve Tables and later expanded, formed the foundation for many modern legal systems. Concepts like innocent until proven guilty and legal representation have their roots in Roman jurisprudence.\n",
        "\n",
        "Decline and Fall\n",
        "The decline of the Roman Empire was a gradual process influenced by internal and external factors. Political instability, economic struggles, and military overreach weakened the empire. The division of the empire into Eastern and Western halves in 395 CE further strained its cohesion. While the Western Roman Empire fell in 476 CE after being overrun by Germanic tribes, the Eastern Roman Empire, known as the Byzantine Empire, endured for another thousand years until the fall of Constantinople in 1453.\n",
        "\n",
        "Legacy\n",
        "The Roman Empire profoundly shaped Western civilization. Its contributions to governance, infrastructure, and culture remain influential today. Latin, the language of Rome, evolved into the Romance languages (Italian, French, Spanish, etc.), and Roman architecture inspired countless generations. The very concept of a republic and the rule of law owe much to Rome’s enduring influence.\n",
        "\n",
        "In essence, the Roman Empire stands as a testament to humanity’s capacity for organization, innovation, and adaptation, making it a cornerstone of global history.\n",
        "\"\"\"\n",
        "\n",
        "# Specify the directory and file name\n",
        "output_dir = \"./data\"\n",
        "file_name = \"roman_empire_overview.txt\"\n",
        "file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "# Ensure the output directory exists; if not, create it\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"Directory '{output_dir}' is ready.\")\n",
        "\n",
        "# Write the text to the file with UTF-8 encoding\n",
        "try:\n",
        "    with open(file_path, 'w', encoding='utf-8') as file:\n",
        "        file.write(roman_empire_text)\n",
        "    print(f\"Text successfully written to '{file_path}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while writing to the file: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76073dab-5f85-4ea7-9fbe-9f0d94e8e86d",
      "metadata": {
        "id": "76073dab-5f85-4ea7-9fbe-9f0d94e8e86d"
      },
      "outputs": [],
      "source": [
        "text_folder = \"data\"\n",
        "texts = []\n",
        "\n",
        "for filename in os.listdir(text_folder):\n",
        "    file_path = os.path.join(text_folder, filename)\n",
        "    if filename.endswith(\".txt\"):\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            texts.append(file.read())\n",
        "    elif filename.endswith(\".pdf\"):\n",
        "        with fitz.open(file_path) as pdf:\n",
        "            pdf_text = \"\"\n",
        "            for page_num in range(pdf.page_count):\n",
        "                page = pdf.load_page(page_num)\n",
        "                pdf_text += page.get_text()\n",
        "            texts.append(pdf_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b772fd-3f04-4f4e-a7f4-26faf2301b64",
      "metadata": {
        "id": "93b772fd-3f04-4f4e-a7f4-26faf2301b64"
      },
      "source": [
        "### Manually add texts to the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5hQSmlQJtgIH",
      "metadata": {
        "id": "5hQSmlQJtgIH"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text, max_tokens=1000):\n",
        "    \"\"\"\n",
        "    Splits text into smaller chunks based on token limit.\n",
        "    Assumes average of ~4 characters per token for rough estimation.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    words = text.split()  # Split text into words\n",
        "    chunk = []\n",
        "    char_count = 0\n",
        "\n",
        "    for word in words:\n",
        "        char_count += len(word) + 1  # Include space\n",
        "        if char_count > max_tokens * 4:  # Estimate max characters per token\n",
        "            chunks.append(\" \".join(chunk))\n",
        "            chunk = []\n",
        "            char_count = len(word) + 1\n",
        "        chunk.append(word)\n",
        "\n",
        "    if chunk:  # Add remaining words\n",
        "        chunks.append(\" \".join(chunk))\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YxnsAwKFICjL",
      "metadata": {
        "id": "YxnsAwKFICjL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from chromadb.api.types import Document\n",
        "import openai\n",
        "\n",
        "def create_and_populate_chroma_db(\n",
        "    data_dir: str = \"./data\",\n",
        "    chroma_db_path: str = \"./chroma_db\",\n",
        "    collection_name: str = \"quickstart\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Creates a ChromaDB collection and populates it with documents from the specified directory.\n",
        "\n",
        "    :param data_dir: Directory containing `.txt` files to be added to ChromaDB.\n",
        "    :param chroma_db_path: Path where ChromaDB data will be stored.\n",
        "    :param collection_name: Name of the ChromaDB collection.\n",
        "    \"\"\"\n",
        "    # Initialize ChromaDB client\n",
        "    client = chromadb.PersistentClient(path=chroma_db_path)\n",
        "    print(f\"ChromaDB client initialized with path '{chroma_db_path}'.\")\n",
        "\n",
        "    # Create or get the collection\n",
        "    collection = client.get_or_create_collection(name=collection_name)\n",
        "    print(f\"ChromaDB collection '{collection_name}' created or retrieved.\")\n",
        "\n",
        "    # Prepare documents\n",
        "    documents = []\n",
        "    embeddings = []\n",
        "    metadatas = []\n",
        "    ids = []\n",
        "\n",
        "    # Ensure OpenAI API key is set\n",
        "    openai.api_key = OPENAI_API_KEY\n",
        "    print(openai.api_key)\n",
        "    for file_name in os.listdir(data_dir):\n",
        "        file_path = os.path.join(data_dir, file_name)\n",
        "        if os.path.isfile(file_path) and file_name.endswith('.txt'):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "                for chunk in chunk_text(content):\n",
        "                  documents.append(content)\n",
        "                  # Create embedding using OpenAI's API\n",
        "                  try:\n",
        "                      response = openai.embeddings.create(input=content, model=\"text-embedding-ada-002\")\n",
        "                      embedding = response.data[0].embedding\n",
        "                      embeddings.append(embedding)\n",
        "                  except Exception as e:\n",
        "                      print(f\"Error creating embedding for '{file_name}': {e}\")\n",
        "                      embeddings.append([])  # Placeholder or handle accordingly\n",
        "                  metadatas.append({\"source\": file_name})\n",
        "                  ids.append(file_name)  # Ensure unique IDs\n",
        "\n",
        "        print(f\"{len(documents)} documents loaded from '{data_dir}'.\")\n",
        "\n",
        "    if not documents:\n",
        "        print(\"No documents found to add to ChromaDB.\")\n",
        "        return\n",
        "\n",
        "    # Add documents to the collection\n",
        "    try:\n",
        "        collection.add(\n",
        "            documents=documents,\n",
        "            metadatas=metadatas,\n",
        "            ids=ids,\n",
        "            embeddings=embeddings\n",
        "        )\n",
        "        print(f\"Documents added to collection '{collection_name}' successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error adding documents to ChromaDB: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_and_populate_chroma_db()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5ry5B2QV7uN",
      "metadata": {
        "id": "c5ry5B2QV7uN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import chromadb\n",
        "\n",
        "def inspect_chroma_db(\n",
        "    chroma_db_path: str = \"./chroma_db\",\n",
        "    collection_name: str = \"quickstart\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Inspect the contents of a ChromaDB collection.\n",
        "\n",
        "    :param chroma_db_path: Path to the ChromaDB storage.\n",
        "    :param collection_name: Name of the ChromaDB collection to inspect.\n",
        "    \"\"\"\n",
        "    # Initialize ChromaDB client\n",
        "    client = chromadb.PersistentClient(path=chroma_db_path)\n",
        "    print(f\"ChromaDB client initialized with path '{chroma_db_path}'.\")\n",
        "\n",
        "    # Retrieve the collection\n",
        "    try:\n",
        "        collection = client.get_collection(name=collection_name)\n",
        "        print(f\"Collection '{collection_name}' retrieved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving collection '{collection_name}': {e}\")\n",
        "        return\n",
        "\n",
        "    # Fetch all data from the collection\n",
        "    try:\n",
        "        data = collection.get()\n",
        "        print(f\"\\nCollection '{collection_name}' contains the following data:\")\n",
        "        ids = data.get(\"ids\", [])\n",
        "        metadatas = data.get(\"metadatas\", [])\n",
        "        documents = data.get(\"documents\", [])\n",
        "        embeddings = data.get(\"embeddings\", [])\n",
        "\n",
        "        for idx, doc_id in enumerate(ids):\n",
        "            print(f\"\\nDocument {idx + 1}:\")\n",
        "            print(f\"  ID: {doc_id}\")\n",
        "            print(f\"  Metadata: {metadatas[idx] if metadatas else 'No metadata'}\")\n",
        "            print(f\"  Document: {documents[idx] if documents else 'No document'}\")\n",
        "            print(f\"  Embedding: {len(embeddings[idx])} values\" if embeddings else \"No embedding\")\n",
        "            print(\"-\" * 40)\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data from collection '{collection_name}': {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    inspect_chroma_db()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vZ7iy3zC9Vm0",
      "metadata": {
        "id": "vZ7iy3zC9Vm0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "def query_chroma_db(\n",
        "    query_text: str,\n",
        "    chroma_db_path: str = \"./chroma_db\",\n",
        "    collection_name: str = \"quickstart\",\n",
        "    top_k: int = 5,\n",
        "    OPENAI_API_KEY=OPENAI_API_KEY\n",
        "):\n",
        "    \"\"\"\n",
        "    Queries the ChromaDB collection and retrieves the top_k most similar documents.\n",
        "\n",
        "    :param query_text: The query string.\n",
        "    :param chroma_db_path: Path to the ChromaDB storage.\n",
        "    :param collection_name: Name of the ChromaDB collection.\n",
        "    :param top_k: Number of top similar documents to retrieve.\n",
        "    \"\"\"\n",
        "    # Initialize ChromaDB client\n",
        "    client = chromadb.PersistentClient(path=chroma_db_path)\n",
        "    print(f\"ChromaDB client initialized with path '{chroma_db_path}'.\")\n",
        "\n",
        "    # Retrieve the collection\n",
        "    collection = client.get_collection(name=collection_name)\n",
        "    if not collection:\n",
        "        raise FileNotFoundError(f\"Collection '{collection_name}' not found in ChromaDB.\")\n",
        "    print(f\"ChromaDB collection '{collection_name}' retrieved.\")\n",
        "\n",
        "    # Define embedding function (must be the same as used during addition)\n",
        "    openai_api_key = OPENAI_API_KEY\n",
        "    if not openai_api_key:\n",
        "        openai_api_key=OPENAI_API_KEY\n",
        "\n",
        "   # Generate embedding for the query\n",
        "    try:\n",
        "        response = openai.embeddings.create(\n",
        "            input=query_text,\n",
        "            model=\"text-embedding-ada-002\"\n",
        "        )\n",
        "        query_embedding = response.data[0].embedding\n",
        "        print(\"Query embedding successfully created.\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error generating embedding for query: {e}\")\n",
        "\n",
        "\n",
        "    # Query the collection\n",
        "    try:\n",
        "        results = collection.query(\n",
        "            query_embeddings=[query_embedding],\n",
        "            n_results=top_k,\n",
        "            include=['metadatas', 'documents']\n",
        "        )\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error querying ChromaDB: {e}\")\n",
        "\n",
        "    # Process results\n",
        "    if not results or 'documents' not in results or not results['documents'][0]:\n",
        "        print(\"No results found.\")\n",
        "        return \"No relevant documents found.\"\n",
        "\n",
        "    # Combine the query with retrieved documents\n",
        "    combined_context = f\"Query: {query_text}\\n\\nRetrieved Documents:\\n\"\n",
        "    for idx, document in enumerate(results['documents'][0]):\n",
        "        metadata = results['metadatas'][0][idx]\n",
        "        source = metadata.get('source', 'Unknown')\n",
        "        combined_context += f\"Document {idx + 1} (Source: {source}):\\n{document}\\n\\n\"\n",
        "\n",
        "    print(f\"Combined context created with {len(results['documents'][0])} documents.\")\n",
        "\n",
        "    # Send the combined context to OpenAI\n",
        "    try:\n",
        "        openai_response = openai.chat.completions.create(\n",
        "            model=\"gpt-4\",  # Use the appropriate model ID for your OpenAI setup\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an assistant that synthesizes answers based on the given context.\"},\n",
        "                {\"role\": \"user\", \"content\": combined_context}\n",
        "            ],\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        synthesized_answer = openai_response.choices[0].message.content.strip()\n",
        "        print(\"Response from OpenAI generated successfully.\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error querying OpenAI: {e}\")\n",
        "\n",
        "    return synthesized_answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "663de93b-ef1e-466a-a8d0-16309706037f",
      "metadata": {
        "id": "663de93b-ef1e-466a-a8d0-16309706037f"
      },
      "source": [
        "### Query the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4SrnNGDg6AaE",
      "metadata": {
        "id": "4SrnNGDg6AaE"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "user_query = \"What are the key achievements of the Roman Empire?\"\n",
        "response = query_chroma_db(user_query)\n",
        "print(\"\\nSynthesized Response from OpenAI:\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
