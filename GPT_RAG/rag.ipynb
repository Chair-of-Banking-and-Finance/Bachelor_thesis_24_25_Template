{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493e40f2-ba94-403e-b7d7-1368f08a5724",
   "metadata": {},
   "source": [
    "## Colab Notebook for Building a RAG System with LLAMAIndex and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d6845-3ea0-482c-8d30-257363b5e8bc",
   "metadata": {},
   "source": [
    "Open this notebook in [colab](https://colab.research.google.com/github/Chair-of-Banking-and-Finance/Bachelor_thesis_24_25_Template/blob/main/GPT_RAG/rag.ipynb)."
  ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae15763-f117-4f0f-bb72-9255539129ff",
   "metadata": {},
   "source": [
    "### Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5166522-0234-48c8-9d6b-3af1f848c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index\n",
    "!pip install openai\n",
    "!pip install faiss-cpu\n",
    "!pip install requests\n",
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab060d-54a5-4c85-8b23-f2f95c8cf384",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01b6dc-4bf9-4b1a-8c56-1182a5836924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import faiss\n",
    "import numpy as np\n",
    "import fitz  # PyMuPDF for PDF handling\n",
    "from llama_index.core import VectorStoreIndex, ServiceContext, PromptTemplate, Document\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57611c79-779f-4495-89f2-405a7a869b82",
   "metadata": {},
   "source": [
    "### Load txt file with the OpenAI key to colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838a20c-255d-42ed-b8d4-14759f5832b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O OPEN_AI_KEY.txt 'https://raw.githubusercontent.com/Chair-of-Banking-and-Finance/Bachelor_thesis_24_25_Template/main/GPT_RAG/OPEN_AI_KEY.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22837c4-42cf-4f64-8b46-b551b1cf1af6",
   "metadata": {},
   "source": [
    "### Insert your OpenAI key and overwrite the file with the new content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7516238c-2b30-4285-a9f7-ec1d74dedb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_content = 'sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "\n",
    "with open('OPEN_AI_KEY.txt', 'w') as file:\n",
    "    file.write(new_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa70c96a-1a62-4c69-9a0f-9c98d98c9b5d",
   "metadata": {},
   "source": [
    "### Load OpenAI API key from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2100b4-10a4-42d3-9091-96e09c8d8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"OPEN_AI_KEY.txt\", \"r\") as key_file:\n",
    "    openai.api_key = key_file.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c365562d-5dd0-4337-ae86-376b1f1156fc",
   "metadata": {},
   "source": [
    "### Create a 'data' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7d112f-7369-4225-85ef-8341d9c45f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab7274-af66-4d90-8302-91ba011ed255",
   "metadata": {},
   "source": [
    "### Load text files and convert PDFs from the \"data\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76073dab-5f85-4ea7-9fbe-9f0d94e8e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_folder = \"data\"\n",
    "texts = []\n",
    "\n",
    "for filename in os.listdir(text_folder):\n",
    "    file_path = os.path.join(text_folder, filename)\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            texts.append(file.read())\n",
    "    elif filename.endswith(\".pdf\"):\n",
    "        with fitz.open(file_path) as pdf:\n",
    "            pdf_text = \"\"\n",
    "            for page_num in range(pdf.page_count):\n",
    "                page = pdf.load_page(page_num)\n",
    "                pdf_text += page.get_text()\n",
    "            texts.append(pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf5143-8074-4348-8bd8-da526194fcb9",
   "metadata": {},
   "source": [
    "### Configure the chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13983a3b-332e-4acf-8d61-7f6c1b65a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1024  # Size of each text chunk\n",
    "chunks = []\n",
    "for text in texts:\n",
    "    chunks.extend([text[i:i+chunk_size] for i in range(0, len(text), chunk_size)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2500ff5-c5fb-4e7c-a149-60bf2f304c25",
   "metadata": {},
   "source": [
    "### Create the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eeb359-ef6c-408c-b767-c047df04c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts):\n",
    "    \"\"\"Embeds text using OpenAI and returns the numpy array of embeddings.\"\"\"\n",
    "    response = openai.Embedding.create(input=texts, model=\"text-embedding-ada-002\")\n",
    "    embeddings = [item['embedding'] for item in response['data']]\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4097c5-138a-4c5c-b602-a8472448818f",
   "metadata": {},
   "source": [
    "### Initialize FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed9b27-2e7e-42ce-a313-fe0f9816b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 1536  # Dimension of the OpenAI embeddings (ensure this matches your model's output)\n",
    "faiss_index = faiss.IndexFlatL2(dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4c209-c7d5-4855-bad4-10c90a5f9492",
   "metadata": {},
   "source": [
    "### Create the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f040b0-9e06-4a04-b341-99accef6e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FaissVectorStore(faiss_index=faiss_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b772fd-3f04-4f4e-a7f4-26faf2301b64",
   "metadata": {},
   "source": [
    "### Manually add texts to the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f8910-03ec-4a19-b690-3b117745a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in chunks:\n",
    "    embedding = embed_texts([chunk])[0]\n",
    "    vector_store.add_vector(embedding, metadata={\"chapter\": \"Introduction\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7517aa-e6de-47b8-9ae1-a9141f330f21",
   "metadata": {},
   "source": [
    "### Simple search method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383789bf-f3fa-45ff-82a9-c7651acd36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, top_k=3):\n",
    "    query_embedding = embed_texts([query])[0]\n",
    "    ids, distances = vector_store.search(query_embedding, top_k=top_k)\n",
    "    return [(chunks[id], distances[i]) for i, id in enumerate(ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663de93b-ef1e-466a-a8d0-16309706037f",
   "metadata": {},
   "source": [
    "### Query the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d41d49-c124-4f1b-a1fb-5e3bbf33e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What happened on November 1st, 1907?\"\n",
    "response = search(query, top_k=3)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
