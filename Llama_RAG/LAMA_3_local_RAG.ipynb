{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2xcXUXrucu74",
      "metadata": {
        "id": "2xcXUXrucu74"
      },
      "source": [
        "# Setting up Google Colab and Hugging Face API\n",
        "\n",
        "Open this notebook in [colab](https://colab.research.google.com/github/Chair-of-Banking-and-Finance/Bachelor_thesis_24_25_Template/blob/main/Llama_RAG/LAMA_3_local_RAG.ipynb).\n",
        "\n",
        "## Getting a Hugging Face API Token\n",
        "1. **Create a Hugging Face account**: Go to [Hugging Face](https://huggingface.co/) and create an account if you don’t already have one.\n",
        "2. **Generate an API Token**: After logging in, click on your profile icon in the top right corner, and go to \"Settings\".\n",
        "3. **Access Tokens**: On the settings page, navigate to the \"Access Tokens\" tab.\n",
        "4. **Create a new token**: Click on \"New Token\", give it a name, and set the role to \"write\". This token will be used to authenticate and download models.\n",
        "5. **Copy the Token**: Copy the generated token and replace the `Hugging_Face_Token` variable in the script with your token.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "m74dgmwyckjo",
      "metadata": {
        "id": "m74dgmwyckjo"
      },
      "outputs": [],
      "source": [
        "Hugging_face_token = \"hf_XXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
        "from huggingface_hub import login\n",
        "login(token=Hugging_face_token)\n",
        "import os\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = Hugging_face_token\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pbDCCz37XwAY",
      "metadata": {
        "id": "pbDCCz37XwAY"
      },
      "source": [
        "Visit [Hugging Face's model page for Llama 2](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf) and request access to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ax0Bg7E1hdSE",
      "metadata": {
        "id": "ax0Bg7E1hdSE"
      },
      "source": [
        "### Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "78d0a4ca-1ce7-4a92-859f-948504ae0c8a",
      "metadata": {
        "collapsed": true,
        "id": "78d0a4ca-1ce7-4a92-859f-948504ae0c8a"
      },
      "outputs": [],
      "source": [
        "# Install basic dependencies\n",
        "!pip install -q transformers\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q torch\n",
        "!pip install -q PyPDF2\n",
        "!pip install -q tqdm\n",
        "!pip install -q hnswlib\n",
        "!pip install -q bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fODkrei7hhMD",
      "metadata": {
        "id": "fODkrei7hhMD"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "oHLGBZmWhjlB",
      "metadata": {
        "id": "oHLGBZmWhjlB"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "import numpy as np\n",
        "import hnswlib\n",
        "from typing import List, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from PyPDF2 import PdfReader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Mp_LJLsiZ-W_",
      "metadata": {
        "id": "Mp_LJLsiZ-W_"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class RetrievedDocument:\n",
        "    \"\"\"Data class for storing retrieved documents and their metadata.\"\"\"\n",
        "    content: str\n",
        "    similarity_score: float\n",
        "    source: str = \"\"\n",
        "\n",
        "class DocumentProcessor:\n",
        "    \"\"\"Handles document loading and preprocessing.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_document(file_path: str) -> Optional[str]:\n",
        "        \"\"\"Load document content from various file formats.\"\"\"\n",
        "        try:\n",
        "            if file_path.endswith('.pdf'):\n",
        "                with open(file_path, 'rb') as file:\n",
        "                    reader = PdfReader(file)\n",
        "                    return ' '.join(page.extract_text() for page in reader.pages)\n",
        "\n",
        "            elif file_path.endswith('.txt'):\n",
        "                with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                    return file.read()\n",
        "            else:\n",
        "                logger.warning(f\"Unsupported file format: {file_path}\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading document {file_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "class HNSWRetriever:\n",
        "    \"\"\"Document retrieval system using HNSWLib for efficient similarity search.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 embedding_model: str = 'BAAI/bge-small-en-v1.5',\n",
        "                 space: str = 'cosine',\n",
        "                 ef_construction: int = 200,\n",
        "                 M: int = 16):\n",
        "        \"\"\"\n",
        "        Initialize the retriever with HNSWLib index.\n",
        "\n",
        "        Args:\n",
        "            embedding_model: Name of the embedding model\n",
        "            space: Distance metric ('cosine', 'l2', 'ip')\n",
        "            ef_construction: Number of neighbors to consider during index construction\n",
        "            M: Number of bi-directional links created for every new element\n",
        "        \"\"\"\n",
        "        self.embedding_model = SentenceTransformer(embedding_model)\n",
        "        self.documents = []\n",
        "        self.document_sources = []\n",
        "        self.index = None\n",
        "        self.space = space\n",
        "        self.ef_construction = ef_construction\n",
        "        self.M = M\n",
        "\n",
        "    def add_documents(self, documents: List[str], sources: List[str] = None) -> None:\n",
        "        \"\"\"Add documents to the retrieval system.\"\"\"\n",
        "        if not documents:\n",
        "            logger.warning(\"No documents provided for indexing\")\n",
        "            return\n",
        "\n",
        "        logger.info(f\"Adding {len(documents)} documents to the index\")\n",
        "\n",
        "        # Store documents and their sources\n",
        "        start_idx = len(self.documents)\n",
        "        self.documents.extend(documents)\n",
        "        if sources:\n",
        "            self.document_sources.extend(sources)\n",
        "\n",
        "        # Create embeddings\n",
        "        embeddings = self.embedding_model.encode(\n",
        "            documents,\n",
        "            show_progress_bar=True,\n",
        "            batch_size=32\n",
        "        )\n",
        "\n",
        "        # Initialize or update HNSWLib index\n",
        "        if self.index is None:\n",
        "            dimension = embeddings.shape[1]\n",
        "            self.index = hnswlib.Index(space=self.space, dim=dimension)\n",
        "            self.index.init_index(\n",
        "                max_elements=len(documents) * 2,  # Allow for future additions\n",
        "                ef_construction=self.ef_construction,\n",
        "                M=self.M\n",
        "            )\n",
        "            self.index.add_items(embeddings, list(range(len(documents))))\n",
        "        else:\n",
        "            self.index.resize_index(len(self.documents))\n",
        "            self.index.add_items(\n",
        "                embeddings,\n",
        "                list(range(start_idx, start_idx + len(documents)))\n",
        "            )\n",
        "\n",
        "        logger.info(\"Documents successfully indexed\")\n",
        "\n",
        "    def retrieve(self, query: str, top_k: int = 3) -> List[RetrievedDocument]:\n",
        "        \"\"\"Retrieve most relevant documents for a query.\"\"\"\n",
        "        if not self.documents:\n",
        "            logger.warning(\"No documents in the index\")\n",
        "            return []\n",
        "\n",
        "        # Encode query\n",
        "        query_embedding = self.embedding_model.encode([query])\n",
        "\n",
        "        # Search index\n",
        "        try:\n",
        "            # Get nearest neighbors\n",
        "            labels, distances = self.index.knn_query(query_embedding, k=min(top_k, len(self.documents)))\n",
        "\n",
        "            # Convert distances to similarities if using cosine space\n",
        "            if self.space == 'cosine':\n",
        "                similarities = 1 - distances[0]\n",
        "            else:\n",
        "                similarities = -distances[0]  # Convert distance to similarity\n",
        "\n",
        "            # Package results\n",
        "            results = []\n",
        "            for idx, similarity in zip(labels[0], similarities):\n",
        "                source = self.document_sources[idx] if self.document_sources else \"\"\n",
        "                results.append(RetrievedDocument(\n",
        "                    content=self.documents[idx],\n",
        "                    similarity_score=float(similarity),\n",
        "                    source=source\n",
        "                ))\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during retrieval: {e}\")\n",
        "            return []\n",
        "\n",
        "class HNSWRAGPipeline:\n",
        "    \"\"\"RAG pipeline using HNSWLib for retrieval.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name: str = 'meta-llama/Llama-2-7b-chat-hf',\n",
        "        embedding_model: str = 'BAAI/bge-small-en-v1.5',\n",
        "        device: str = 'auto',\n",
        "        load_in_4bit: bool = True\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the RAG pipeline.\n",
        "\n",
        "        Args:\n",
        "            model_name: Name of the language model to use\n",
        "            embedding_model: Name of the embedding model\n",
        "            device: Device to use ('auto', 'cuda', 'cpu')\n",
        "            load_in_4bit: Whether to load model in 4-bit precision\n",
        "        \"\"\"\n",
        "        logger.info(f\"Initializing HNSWRAGPipeline with model: {model_name}\")\n",
        "\n",
        "        # Initialize retriever\n",
        "        self.retriever = HNSWRetriever(embedding_model)\n",
        "\n",
        "        # Initialize tokenizer and model\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                model_name,\n",
        "                use_fast=True,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            if device == 'auto':\n",
        "                device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "            # Configure model loading based on available resources\n",
        "            model_kwargs = {\n",
        "                \"device_map\": device,\n",
        "                \"torch_dtype\": torch.float16 if device == 'cuda' else torch.float32,\n",
        "                \"low_cpu_mem_usage\": True\n",
        "            }\n",
        "\n",
        "            if device == 'cuda' and load_in_4bit:\n",
        "                try:\n",
        "                    from transformers import BitsAndBytesConfig\n",
        "\n",
        "                    model_kwargs.update({\n",
        "                        \"quantization_config\": BitsAndBytesConfig(\n",
        "                            load_in_4bit=True,\n",
        "                            bnb_4bit_compute_dtype=torch.float16,\n",
        "                            bnb_4bit_use_double_quant=True,\n",
        "                            bnb_4bit_quant_type=\"nf4\"\n",
        "                        )\n",
        "                    })\n",
        "                except ImportError:\n",
        "                    logger.warning(\"bitsandbytes not available, falling back to 16-bit\")\n",
        "\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_name,\n",
        "                **model_kwargs\n",
        "            )\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading model: {e}\")\n",
        "            raise\n",
        "\n",
        "        logger.info(\"Pipeline initialized successfully\")\n",
        "\n",
        "    def add_documents(self, file_paths: List[str]) -> None:\n",
        "        \"\"\"Add documents to the retrieval system.\"\"\"\n",
        "        documents = []\n",
        "        valid_sources = []\n",
        "\n",
        "        for path in tqdm(file_paths, desc=\"Loading documents\"):\n",
        "            content = DocumentProcessor.load_document(path)\n",
        "            if content:\n",
        "                documents.append(content)\n",
        "                valid_sources.append(path)\n",
        "\n",
        "        self.retriever.add_documents(documents, valid_sources)\n",
        "\n",
        "    def _format_prompt(self, query: str, retrieved_docs: List[RetrievedDocument]) -> str:\n",
        "        \"\"\"Format the prompt with retrieved context.\"\"\"\n",
        "        context_str = \"\\n\\n\".join(\n",
        "            f\"[Document {i+1} (Relevance: {doc.similarity_score:.2f})]\\n{doc.content}\"\n",
        "            for i, doc in enumerate(retrieved_docs)\n",
        "        )\n",
        "\n",
        "        return f\"\"\"[INST]\n",
        "Using the following retrieved documents as context, please answer the question.\n",
        "If the context doesn't contain relevant information, use your general knowledge\n",
        "but indicate this in your response.\n",
        "\n",
        "Context:\n",
        "{context_str}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Please provide a comprehensive and accurate answer based on the provided context.\n",
        "If the context is insufficient, indicate what information comes from your general knowledge.[/INST]\"\"\"\n",
        "\n",
        "    def generate_response(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        max_new_tokens: int = 512,\n",
        "        temperature: float = 0.7,\n",
        "        top_p: float = 0.9\n",
        "    ) -> str:\n",
        "        \"\"\"Generate a response using the language model.\"\"\"\n",
        "        try:\n",
        "            inputs = self.tokenizer(\n",
        "                prompt,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                max_length=2048\n",
        "            ).to(self.model.device)\n",
        "\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                temperature=temperature,\n",
        "                top_p=top_p,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            response = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating response: {e}\")\n",
        "            return \"I apologize, but I encountered an error while generating the response.\"\n",
        "\n",
        "    def query(\n",
        "        self,\n",
        "        query: str,\n",
        "        top_k: int = 3,\n",
        "        max_new_tokens: int = 512\n",
        "    ) -> Tuple[str, List[RetrievedDocument]]:\n",
        "        \"\"\"Process a query through the complete RAG pipeline.\"\"\"\n",
        "        logger.info(f\"Processing query: {query}\")\n",
        "\n",
        "        # Retrieve relevant documents\n",
        "        retrieved_docs = self.retriever.retrieve(query, top_k=top_k)\n",
        "\n",
        "        if not retrieved_docs:\n",
        "            logger.warning(\"No relevant documents found\")\n",
        "            prompt = f\"\"\"[INST]Please answer this question using your general knowledge:\n",
        "{query}[/INST]\"\"\"\n",
        "        else:\n",
        "            prompt = self._format_prompt(query, retrieved_docs)\n",
        "\n",
        "        # Generate response\n",
        "        response = self.generate_response(prompt, max_new_tokens=max_new_tokens)\n",
        "\n",
        "        return response, retrieved_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "I-X41Xi9g6A4",
      "metadata": {
        "id": "I-X41Xi9g6A4"
      },
      "outputs": [],
      "source": [
        "# Define the text to be written to the file\n",
        "roman_empire_text = \"\"\"\n",
        "The Roman Empire: An Overview\n",
        "The Roman Empire was one of the most influential civilizations in human history, spanning over a millennium and leaving a legacy that shaped the world in areas such as governance, architecture, engineering, and law. Officially beginning in 27 BCE with the rise of Augustus Caesar, Rome transitioned from a republic to an empire, dominating vast territories that stretched from Britain in the northwest to Egypt in the southeast.\n",
        "\n",
        "Formation and Expansion\n",
        "The Roman Empire's foundation was built on centuries of conquest during the Roman Republic. Under Augustus, the empire ushered in a period of peace and stability known as the Pax Romana (Roman Peace), lasting about 200 years. During this time, Rome expanded its borders, solidifying control over Europe, North Africa, and parts of the Middle East.\n",
        "\n",
        "The empire was characterized by a vast network of cities connected by advanced roads and aqueducts, facilitating trade, military movements, and cultural exchange. Notable conquests include Gaul (modern-day France) under Julius Caesar, the annexation of Egypt after Cleopatra's defeat, and the consolidation of power in regions such as Spain and the Balkans.\n",
        "\n",
        "Culture and Society\n",
        "Roman society was highly stratified, with a clear distinction between the elite patricians, common plebeians, and enslaved individuals. Roman culture blended Latin traditions with influences from Greece and the regions it conquered. This fusion led to remarkable achievements in literature (Virgil’s Aeneid), philosophy (Cicero, Seneca), and architecture (the Colosseum, aqueducts, and the Pantheon).\n",
        "\n",
        "The Roman Empire was also a melting pot of religions. Initially polytheistic, it later became a cradle for Christianity, with Emperor Constantine legalizing the faith in 313 CE and Emperor Theodosius I declaring it the state religion by 380 CE.\n",
        "\n",
        "Governance and Law\n",
        "Rome was renowned for its administrative prowess and legal systems. The empire was divided into provinces, each governed by an appointed official. Roman law, codified in the Twelve Tables and later expanded, formed the foundation for many modern legal systems. Concepts like innocent until proven guilty and legal representation have their roots in Roman jurisprudence.\n",
        "\n",
        "Decline and Fall\n",
        "The decline of the Roman Empire was a gradual process influenced by internal and external factors. Political instability, economic struggles, and military overreach weakened the empire. The division of the empire into Eastern and Western halves in 395 CE further strained its cohesion. While the Western Roman Empire fell in 476 CE after being overrun by Germanic tribes, the Eastern Roman Empire, known as the Byzantine Empire, endured for another thousand years until the fall of Constantinople in 1453.\n",
        "\n",
        "Legacy\n",
        "The Roman Empire profoundly shaped Western civilization. Its contributions to governance, infrastructure, and culture remain influential today. Latin, the language of Rome, evolved into the Romance languages (Italian, French, Spanish, etc.), and Roman architecture inspired countless generations. The very concept of a republic and the rule of law owe much to Rome’s enduring influence.\n",
        "\n",
        "In essence, the Roman Empire stands as a testament to humanity’s capacity for organization, innovation, and adaptation, making it a cornerstone of global history.\n",
        "\"\"\"\n",
        "\n",
        "# Specify the directory and file name\n",
        "output_dir = \"./data\"\n",
        "file_name = \"roman_empire_overview.txt\"\n",
        "file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "# Ensure the output directory exists; if not, create it\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Write the text to the file with UTF-8 encoding\n",
        "with open(file_path, 'w', encoding='utf-8') as file:\n",
        "    file.write(roman_empire_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4GU9cGpPNW52",
      "metadata": {
        "id": "4GU9cGpPNW52"
      },
      "outputs": [],
      "source": [
        "# First, clear any existing CUDA memory\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "x_gnBpZng8ty",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "45d517d0381c43c0b8b224fded14f4d2",
            "4149656e91ba4cc5a85a21585ba27b6c",
            "099bb604a4614ac0bc9ad78e78325bcb",
            "87d0526d96854679acd2857108497b3e",
            "b2249480a00341188af3ea2c4b419ebc",
            "44969f534af94e44b3e340e75d3eeb58",
            "4b8d6f5ba54b4df39edfb18afa8d4d18",
            "17a35e8fe7d149f8a6c0e5ecd5e62463",
            "3014a25fc0eb4efca36947a06a82b75e",
            "c739b73f49bc4dafa4dcc9435d790804",
            "656269b37ac84cb18e0140348a4b63a0"
          ]
        },
        "id": "x_gnBpZng8ty",
        "outputId": "2a185dd2-cc26-4f83-9c33-03256f96f6c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45d517d0381c43c0b8b224fded14f4d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize pipeline forcing CPU mode for all components\n",
        "rag = HNSWRAGPipeline(\n",
        "    model_name='meta-llama/Llama-2-7b-chat-hf'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "x7t2VEbKPYNK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507,
          "referenced_widgets": [
            "49c2baa286ec4f32b8603ae2e4c57f62",
            "15e4848179fa4433abe587b0d200e92c",
            "82ea517e140e4a2183372ee2aee114a0",
            "c36474c69e4a44f3b354b8edbe7c9238",
            "d8a8002de67949369bf536fad83fa3f8",
            "6fcc9c60037f434baca5edeb09c26064",
            "750ab258613d44549e3eeb35642d8b5f",
            "4768facc69564fd8812dfd9f9eec3aa6",
            "590b07b458c842ba96a6a31fd9af693f",
            "9674b5d33bc64b35ad720292e6d154a2",
            "24a5417becdd4d4eac86cb7d0bf0e6d2"
          ]
        },
        "id": "x7t2VEbKPYNK",
        "outputId": "1edac833-603b-49ba-a56c-75544e38ae3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading documents: 100%|██████████| 1/1 [00:00<00:00, 62.21it/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49c2baa286ec4f32b8603ae2e4c57f62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: What were the major achievements of the Roman Empire?\n",
            "\n",
            "Retrieved Documents:\n",
            "\n",
            "Document 1 (Similarity: 0.76)\n",
            "Source: data/roman_empire_overview.txt\n",
            "Preview: \n",
            "The Roman Empire: An Overview\n",
            "The Roman Empire was one of the most influential civilizations in human history, spanning over a millennium and leaving a legacy that shaped the world in areas such as g...\n",
            "\n",
            "Generated Response:\n",
            "Based on the provided context, the major achievements of the Roman Empire can be summarized as follows:\n",
            "\n",
            "1. Governance: The Roman Empire was renowned for its administrative prowess and legal systems. The empire was divided into provinces, each governed by an appointed official, and Roman law, codified in the Twelve Tables and later expanded, formed the foundation for many modern legal systems.\n",
            "2. Infrastructure: The Roman Empire was characterized by a vast network of cities connected by advanced roads and aqueducts, facilitating trade, military movements, and cultural exchange. The empire's engineering feats, such as the construction of the Colosseum, the Pantheon, and aqueducts, remain impressive to this day.\n",
            "3. Culture and Society: Roman society was highly stratified, with a clear distinction between the elite patricians, common plebeians, and enslaved individuals. Roman culture blended Latin traditions with influences from Greece and the regions it conquered, leading to remarkable achievements in literature (e.g., Virgil's Aeneid), philosophy (e.g., Cicero, Seneca), and architecture (e.g., the Colosseum, aqueducts, and the Pantheon). The Roman Empire was also a melting pot of religions, with Christianity eventually becoming the state religion.\n",
            "4. Expansion: The empire expanded its borders through centuries of conquest during the Roman Republic, solidifying control over Europe, North Africa, and parts of the Middle East. Notable conquests include Gaul (modern-day France) under Julius Caesar and the annexation of Egypt after Cleopatra's defeat.\n",
            "5. Legacy: The Roman Empire profoundly shaped Western civilization, contributing to governance, infrastructure, and culture in lasting ways. Latin, the language of Rome, evolved into the Romance languages, and Roman architecture inspired countless generations. The very concept of a republic and the rule of law owe much to Rome's enduring influence.\n",
            "\n",
            "While the context does not provide information on the Roman Empire's military achievements, it is well-documented that the empire's military prowess was a significant factor in its expansion and maintenance of power.\n",
            "\n",
            "It is worth noting that the Roman Empire'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "document_dir = \"data\"\n",
        "# Get document files\n",
        "document_files = [\n",
        "    os.path.join(document_dir, f)\n",
        "    for f in os.listdir(document_dir)\n",
        "    if os.path.isfile(os.path.join(document_dir, f))\n",
        "]\n",
        "rag.add_documents(document_files)\n",
        "\n",
        "# Example query\n",
        "query = \"What were the major achievements of the Roman Empire?\"\n",
        "response, retrieved_docs = rag.query(query)\n",
        "\n",
        "print(f\"\\nQuery: {query}\")\n",
        "print(\"\\nRetrieved Documents:\")\n",
        "for i, doc in enumerate(retrieved_docs, 1):\n",
        "    print(f\"\\nDocument {i} (Similarity: {doc.similarity_score:.2f})\")\n",
        "    print(f\"Source: {doc.source}\")\n",
        "    print(f\"Preview: {doc.content[:200]}...\")\n",
        "\n",
        "print(\"\\nGenerated Response:\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sHInblQnGjJ2",
      "metadata": {
        "id": "sHInblQnGjJ2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "099bb604a4614ac0bc9ad78e78325bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17a35e8fe7d149f8a6c0e5ecd5e62463",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3014a25fc0eb4efca36947a06a82b75e",
            "value": 2
          }
        },
        "15e4848179fa4433abe587b0d200e92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fcc9c60037f434baca5edeb09c26064",
            "placeholder": "​",
            "style": "IPY_MODEL_750ab258613d44549e3eeb35642d8b5f",
            "value": "Batches: 100%"
          }
        },
        "17a35e8fe7d149f8a6c0e5ecd5e62463": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24a5417becdd4d4eac86cb7d0bf0e6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3014a25fc0eb4efca36947a06a82b75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4149656e91ba4cc5a85a21585ba27b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44969f534af94e44b3e340e75d3eeb58",
            "placeholder": "​",
            "style": "IPY_MODEL_4b8d6f5ba54b4df39edfb18afa8d4d18",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "44969f534af94e44b3e340e75d3eeb58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d517d0381c43c0b8b224fded14f4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4149656e91ba4cc5a85a21585ba27b6c",
              "IPY_MODEL_099bb604a4614ac0bc9ad78e78325bcb",
              "IPY_MODEL_87d0526d96854679acd2857108497b3e"
            ],
            "layout": "IPY_MODEL_b2249480a00341188af3ea2c4b419ebc"
          }
        },
        "4768facc69564fd8812dfd9f9eec3aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c2baa286ec4f32b8603ae2e4c57f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15e4848179fa4433abe587b0d200e92c",
              "IPY_MODEL_82ea517e140e4a2183372ee2aee114a0",
              "IPY_MODEL_c36474c69e4a44f3b354b8edbe7c9238"
            ],
            "layout": "IPY_MODEL_d8a8002de67949369bf536fad83fa3f8"
          }
        },
        "4b8d6f5ba54b4df39edfb18afa8d4d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "590b07b458c842ba96a6a31fd9af693f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "656269b37ac84cb18e0140348a4b63a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fcc9c60037f434baca5edeb09c26064": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "750ab258613d44549e3eeb35642d8b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82ea517e140e4a2183372ee2aee114a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4768facc69564fd8812dfd9f9eec3aa6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_590b07b458c842ba96a6a31fd9af693f",
            "value": 1
          }
        },
        "87d0526d96854679acd2857108497b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c739b73f49bc4dafa4dcc9435d790804",
            "placeholder": "​",
            "style": "IPY_MODEL_656269b37ac84cb18e0140348a4b63a0",
            "value": " 2/2 [01:16&lt;00:00, 35.03s/it]"
          }
        },
        "9674b5d33bc64b35ad720292e6d154a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2249480a00341188af3ea2c4b419ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c36474c69e4a44f3b354b8edbe7c9238": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9674b5d33bc64b35ad720292e6d154a2",
            "placeholder": "​",
            "style": "IPY_MODEL_24a5417becdd4d4eac86cb7d0bf0e6d2",
            "value": " 1/1 [00:01&lt;00:00,  1.23s/it]"
          }
        },
        "c739b73f49bc4dafa4dcc9435d790804": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a8002de67949369bf536fad83fa3f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
